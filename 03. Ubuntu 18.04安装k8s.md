# Ubuntu 18.04安装K8S

## 调整参数

```bash
itux@k8s01:~> sudo vi /etc/default/grub
GRUB_CMDLINE_LINUX="cgroup_enable=memory swapaccount=1"
itux@k8s01:~> sudo update-grub
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-4.15.0-23-generic
Found initrd image: /boot/initrd.img-4.15.0-23-generic
Found linux image: /boot/vmlinuz-4.15.0-22-generic
Found initrd image: /boot/initrd.img-4.15.0-22-generic
Found linux image: /boot/vmlinuz-4.15.0-20-generic
Found initrd image: /boot/initrd.img-4.15.0-20-generic
done
itux@k8s01:~> sudo reboot
```

* 解决`May 30 23:34:57 k8s01 dockerd[764]: time="2018-05-30T23:34:57.012693725+08:00" level=warning msg="Your kernel does not support swap limit capabilities,or the cgroup is not mounted. Memory limited without swap."` 告警；
* 在其他节点上也重复该步骤；

## 安装docker

```bash
itux@k8s01:~>  sudo apt-get install docker.io
itux@k8s01:~>  sudo systemctl start docker
itux@k8s01:~>  sudo systemctl enable docker
```

* 在其他节点上重复该步骤安装docker软件包；

## 安装kubernetes

```bash
itux@k8s01:~>  curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -
itux@k8s01:~>  sudo vi /etc/apt/sources.list.d/kubernetes.list
itux@k8s01:~>  deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
itux@k8s01:~>  sudo apt-get update && sudo apt-get install -y kubelet kubeadm kubectl
```

* 在其他节点上重复该步骤安装软件包；

## 安装crictl

```bash
itux@k8s01:~> wget https://github.com/kubernetes-incubator/cri-tools/releases/download/v1.0.0-beta.1/crictl-v1.0.0-beta.1-linux-amd64.tar.gz
itux@k8s01:~> tar xvf crictl-v1.0.0-beta.1-linux-amd64.tar.gz
itux@k8s01:~> sudo chown root:root crictl
itux@k8s01:~> sudo cp crictl /usr/bin
itux@k8s01:~> scp crictl itux@k8s02:/home/itux

itux@k8s02:~> sudo chown root:root crictl
itux@k8s02:~> sudo mv crictl /usr/bin/
```

* kubeadm需要crictl工具；

## kubeadm初始化集群

```bash
itux@k8s01:~> sudo kubeadm init --apiserver-advertise-address=172.16.1.10  --pod-network-cidr=10.244.0.0/16 --feature-gates=CoreDNS=true
[init] Using Kubernetes version: v1.10.3
[init] Using Authorization modes: [Node RBAC]
[preflight] Running pre-flight checks.
  [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 17.12.1-ce. Max validated version: 17.03
[preflight] Starting the kubelet service
[certificates] Generated ca certificate and key.
[certificates] Generated apiserver certificate and key.
[certificates] apiserver serving cert is signed for DNS names [k8s01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.1.10]
[certificates] Generated apiserver-kubelet-client certificate and key.
[certificates] Generated etcd/ca certificate and key.
[certificates] Generated etcd/server certificate and key.
[certificates] etcd/server serving cert is signed for DNS names [localhost] and IPs [127.0.0.1]
[certificates] Generated etcd/peer certificate and key.
[certificates] etcd/peer serving cert is signed for DNS names [k8s01] and IPs [172.16.1.10]
[certificates] Generated etcd/healthcheck-client certificate and key.
[certificates] Generated apiserver-etcd-client certificate and key.
[certificates] Generated sa key and public key.
[certificates] Generated front-proxy-ca certificate and key.
[certificates] Generated front-proxy-client certificate and key.
[certificates] Valid certificates and keys now exist in "/etc/kubernetes/pki"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/admin.conf"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/kubelet.conf"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/controller-manager.conf"
[kubeconfig] Wrote KubeConfig file to disk: "/etc/kubernetes/scheduler.conf"
[controlplane] Wrote Static Pod manifest for component kube-apiserver to "/etc/kubernetes/manifests/kube-apiserver.yaml"
[controlplane] Wrote Static Pod manifest for component kube-controller-manager to "/etc/kubernetes/manifests/kube-controller-manager.yaml"
[controlplane] Wrote Static Pod manifest for component kube-scheduler to "/etc/kubernetes/manifests/kube-scheduler.yaml"
[etcd] Wrote Static Pod manifest for a local etcd instance to "/etc/kubernetes/manifests/etcd.yaml"
[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory "/etc/kubernetes/manifests".
[init] This might take a minute or longer if the control plane images have to be pulled.
[apiclient] All control plane components are healthy after 22.007108 seconds
[uploadconfig] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[markmaster] Will mark node k8s01 as master by adding a label and a taint
[markmaster] Master k8s01 tainted and labelled with key/value: node-role.kubernetes.io/master=""
[bootstraptoken] Using token: q6mcr8.td3pbmccy20ajy7m
[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join 172.16.1.10:6443 --token q6mcr8.td3pbmccy20ajy7m --discovery-token-ca-cert-hash sha256:fa69fcc99388c881a796d7f22239a304f32dff9d2ea542316c4f9bc33b81ca32
```

* 建议不要在kubeadm init时设置`--service-cidr`参数，kubelet默认会使用10.96.0.10作为`--cluster-dns`地址，设置参数后，pod将无法查询dns，需要每个节点修改kubelet的`--cluster-dns`参数才能让pod查询dns。

## 设置kubectl

```bash
itux@k8s01:~> mkdir -p $HOME/.kube
itux@k8s01:~> sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
itux@k8s01:~> sudo chown $(id -u):$(id -g) $HOME/.kube/config
itux@k8s01:~> kubectl completion bash |sudo tee /etc/bash_completion.d/kubectl
```

## 安装flannel

```bash
itux@k8s01:~> sudo vi /etc/sysctl.conf
net.bridge.bridge-nf-call-iptables = 1
itux@k8s01:~> sudo sysctl -p
net.bridge.bridge-nf-call-iptables = 1
itux@k8s01:~> kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml
clusterrole.rbac.authorization.k8s.io "flannel" created
clusterrolebinding.rbac.authorization.k8s.io "flannel" created
serviceaccount "flannel" created
configmap "kube-flannel-cfg" created
daemonset.extensions "kube-flannel-ds" created
```

* 在其他节点上也要设置`net.bridge.bridge-nf-call-iptables = 1`；

## 将master节点加入调度

```bash
itux@k8s01:~> kubectl taint nodes --all node-role.kubernetes.io/master-
node "k8s01" untainted
```

## 将其他节点加入集群

```bash
itux@k8s02:~> sudo kubeadm join 172.16.1.10:6443 --token q6mcr8.td3pbmccy20ajy7m --discovery-token-ca-cert-hash sha256:fa69fcc99388c881a796d7f22239a304f32dff9d2ea542316c4f9bc33b81ca32 --ignore-preflight-errors=cri
[preflight] Running pre-flight checks.
  [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 17.12.1-ce. Max validated version: 17.03
  [WARNING CRI]: unable to check if the container runtime at "/var/run/dockershim.sock" is running: exit status 1
[preflight] Starting the kubelet service
[discovery] Trying to connect to API Server "172.16.1.10:6443"
[discovery] Created cluster-info discovery client, requesting info from "https://172.16.1.10:6443"
[discovery] Requesting info from "https://172.16.1.10:6443" again to validate TLS against the pinned public key
[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server "172.16.1.10:6443"
[discovery] Successfully established connection with API Server "172.16.1.10:6443"

This node has joined the cluster:
* Certificate signing request was sent to master and a response
  was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the master to see this node join the cluster.
```

* kubeadm join时使用`--ignore-preflight-errors=cri`解决`/var/run/dockershim.sock`不存在，节点无法接入集群的问题。
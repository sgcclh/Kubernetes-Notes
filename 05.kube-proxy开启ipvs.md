# kube-proxy开启ipvs(可选)

## 参考链接

[kube-proxy ipvs](https://github.com/kubernetes/kubernetes/tree/master/pkg/proxy/ipvs)

## 安装ipvsadm

```bash
#  yum install ipvsadm
```

* 所有节点安装ipvsadm工具，用于查看ipvs规则。

## 服务器加载ipvs相关内核模块

```bash
# vi /etc/modules-load.d/ipvs.conf
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack_ipv4
# systemctl start systemd-modules-load.service
```

* 在所有node节点加载ipvs内核模块，在CentOS 7.4中已经安装了这些内核模块只需加载即可。

## 修改kube-proxy启动参数

```bash
# vi /usr/lib/systemd/system/kube-proxy.service
[Unit]
Description=Kubernetes Kube-Proxy Server
After=network.target

[Service]
WorkingDirectory=/var/lib/kube-proxy
ExecStart=/usr/bin/kube-proxy \
  --bind-address=172.16.1.10 \
  --masquerade-all=true \
  --feature-gates=SupportIPVSProxyMode=true \
  --proxy-mode=ipvs \
  --cluster-cidr=10.253.0.0/16 \
  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \
  --logtostderr=true \
  --log-dir=/var/log/kubernetes \
  --v=2
Restart=on-failure
RestartSec=5
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
```

* 在所有节点调整kube-proxy启动参数，加入--masquerade-all=true、--feature-gates=SupportIPVSProxyMode=true、--proxy-mode=ipvs启动参数，--bind-address根据node节点的实际ip更改；
* 由于ipvs采用nat模式，因此需要--masquerade-all=true参数来保证返回数据包能被通过；
* --feature-gates=SupportIPVSProxyMode=true开启ipvs proxy特性，在后续的1.10版本的k8s中，默认为true，但1.9.x版本仍然需要在kube-proxy启动参数中开启ipvs特性；
* --proxy-mode=ipvs指定kube-proxy使用ipvs模式。

## 重启kube-proxy服务

```bash
# systemctl daemon-reload
# systemctl restart kube-proxy
# systemctl status kube-proxy.service
● kube-proxy.service - Kubernetes Kube-Proxy Server
   Loaded: loaded (/usr/lib/systemd/system/kube-proxy.service; enabled; vendor preset: disabled)
   Active: active (running) since Thu 2018-05-03 15:43:49 CST; 29min ago
 Main PID: 15366 (kube-proxy)
    Tasks: 0
   Memory: 12.7M
   CGroup: /system.slice/kube-proxy.service
           ‣ 15366 /usr/bin/kube-proxy --bind-address=172.16.1.10 --masquerade-all=true --feature-gates=SupportIPVSProxyMode=true --proxy-mode=ipvs --cluster-cidr=10.253.0.0/16 --kubeconfi...

May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.062622   15366 proxier.go:416] Adding new service port "default/heketi:heketi" at 10.254.111.142:8080/TCP
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.062632   15366 proxier.go:416] Adding new service port "ingress-nginx/default-http-backend:" at 10.254.94.117:80/TCP
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.062648   15366 proxier.go:416] Adding new service port "kube-system/heapster:" at 10.254.204.85:80/TCP
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.062658   15366 proxier.go:416] Adding new service port "kube-system/kube-dns:dns" at 10.254.0.2:53/UDP
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.062667   15366 proxier.go:416] Adding new service port "kube-system/kube-dns:dns-tcp" at 10.254.0.2:53/TCP
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.062788   15366 proxier.go:956] Stale udp service kube-system/kube-dns:dns -> 10.254.0.2
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.125092   15366 proxier.go:1829] Opened local port "nodePort for ingress-nginx/ingress-nginx:https" (:30443/tcp)
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.131671   15366 proxier.go:1829] Opened local port "nodePort for kube-system/kubernetes-dashboard:" (:32767/tcp)
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.134574   15366 proxier.go:1829] Opened local port "nodePort for kube-system/monitoring-grafana:" (:32766/tcp)
May 03 15:43:50 k8s01 kube-proxy[15366]: I0503 15:43:50.136610   15366 proxier.go:1829] Opened local port "nodePort for ingress-nginx/ingress-nginx:http" (:30080/tcp)

[root@k8s01 ~]# ip addr show dev kube-ipvs0
14: kube-ipvs0: <BROADCAST,NOARP> mtu 1500 qdisc noop state DOWN
    link/ether 3e:51:a8:63:06:63 brd ff:ff:ff:ff:ff:ff
    inet 10.254.204.85/32 brd 10.254.204.85 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.122.20/32 brd 10.254.122.20 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.112.177/32 brd 10.254.112.177 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.227.68/32 brd 10.254.227.68 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.174.122/32 brd 10.254.174.122 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.111.142/32 brd 10.254.111.142 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.0.2/32 brd 10.254.0.2 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.167.37/32 brd 10.254.167.37 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.0.1/32 brd 10.254.0.1 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
    inet 10.254.94.117/32 brd 10.254.94.117 scope global kube-ipvs0
       valid_lft forever preferred_lft forever
```

## 测试ipvs模式

```bash
[root@k8s01 ~]# kubectl get svc heketi
NAME      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
heketi    ClusterIP   10.254.111.142   <none>        8080/TCP   8d
[root@k8s01 ~]# curl 10.254.111.142:8080/hello
Hello from Heketi
[root@k8s01 ~]# vi pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.7.9
    ports:
    - containerPort: 80
[root@k8s01 ~]# kubectl create -f pod.yaml
[root@k8s01 ~]# kubectl exec -it nginx bash
root@nginx:/# ping heketi
PING heketi.default.svc.cluster.local (10.254.111.142): 48 data bytes
56 bytes from 10.254.111.142: icmp_seq=0 ttl=64 time=0.216 ms
56 bytes from 10.254.111.142: icmp_seq=1 ttl=64 time=0.118 ms
56 bytes from 10.254.111.142: icmp_seq=2 ttl=64 time=0.192 ms
^C--- heketi.default.svc.cluster.local ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max/stddev = 0.118/0.175/0.216/0.042 ms

root@nginx:/# ping kubernetes
PING kubernetes.default.svc.cluster.local (10.254.0.1): 48 data bytes
56 bytes from 10.254.0.1: icmp_seq=0 ttl=64 time=0.116 ms
^C--- kubernetes.default.svc.cluster.local ping statistics ---
1 packets transmitted, 1 packets received, 0% packet loss
round-trip min/avg/max/stddev = 0.116/0.116/0.116/0.000 ms

root@nginx:/# ping kube-dns.kube-system.svc.cluster.local
PING kube-dns.kube-system.svc.cluster.local (10.254.0.2): 48 data bytes
56 bytes from 10.254.0.2: icmp_seq=0 ttl=64 time=0.232 ms
56 bytes from 10.254.0.2: icmp_seq=1 ttl=64 time=0.129 ms
^C--- kube-dns.kube-system.svc.cluster.local ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max/stddev = 0.129/0.180/0.232/0.052 ms
```